{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "colonial-cloud",
   "metadata": {},
   "source": [
    "# Construire une droite d'étalonnage\n",
    "\n",
    "On se propose de donner quelques éléments supplémentaires pour la régression linéaire, notamment pour son utilisation pour estimer une valeur (comme avec une courbe d'étalonnage). On se base ici sur un exemple de chimie : l'utilisation d'une courbe d'étalonnage reliant l'absorbance à la concentration d'une espèce colorée.\n",
    "\n",
    "Cette partie est plus optionnelle et demande déjà une bonne compréhension des éléments précédents, notamment sur la régression linéaire et l'utilisation des fonctions Python.\n",
    "\n",
    "## Données de mesures\n",
    "Les données déjà utilisées sont disponibles en ligne. On va directement charger les données depuis le fichier en ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-robert",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "../../../../../approche_numeriques/donnees_exp/lambert.dat not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a8ada5890861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# filename = \"https://github.com/pcsi3physiquestan/donnees_exp/blob/main/lambert.dat?raw=true\"  # Lien vers le fichier de données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../../../../../approche_numeriques/donnees_exp/lambert.dat\"\u001b[0m  \u001b[0;31m# Lien vers le fichier de données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Importation des données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/jupybook/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupybook/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/jupybook/lib/python3.9/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    533\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: ../../../../../approche_numeriques/donnees_exp/lambert.dat not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rd\n",
    "\n",
    "\n",
    "# filename = \"https://github.com/pcsi3physiquestan/donnees_exp/blob/main/lambert.dat?raw=true\"  # Lien vers le fichier de données\n",
    "filename = \"../../../../../approche_numeriques/donnees_exp/lambert.dat\"  # Lien vers le fichier de données\n",
    "A, C, uC = np.loadtxt(filename, skiprows=1, delimiter=\",\", unpack=True)  # Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-genesis",
   "metadata": {},
   "source": [
    "## Vérification visuelle de la loi linéaire\n",
    "Avant de se lancer dans une régression linéaire et la simulation de Monte-Carlo, on va vérifier que le modèle affine est acceptable visuellement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Détermination des moyennes et écart-type pour la simulation de Monte-Carlo puis création des N échantillons\n",
    "\"\"\"\n",
    "n_mes = A.shape[0]  # Nombre de mesures réalisées\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Vérification visuelle de l'alignement (approximatifs) des points de mesure.\n",
    "\"\"\"\n",
    "f, ax = plt.subplots()\n",
    "f.suptitle(\"Test visuel de l'alignement des points\")\n",
    "ax.set_xlabel(\"A(SI)\")\n",
    "ax.set_ylabel(\"C(10^-5 mol/L)\")\n",
    "\n",
    "ax.errorbar(A, C, yerr=uC, marker='+', markersize=2, linestyle='')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-conducting",
   "metadata": {},
   "source": [
    "## Mise en place de la simulation de Monte-Carlo\n",
    "On commence par réaliser les N échantillons simulées pour A et C. Sans plus d'information, on a choisi des distributions gaussiennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation des N tirages\n",
    "N = 1000000\n",
    "C_sim = rd.normal(C, uC, (N, n_mes))  # On génère directement un tableau où les colonnes correspondent à une mesure de C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-advocacy",
   "metadata": {},
   "source": [
    "## Paramètres d'ajustement\n",
    "On va donc réaliser N régressions linéaires et ainsi estimer la pente et l'ordonnée à l'origine avec leurs incertitudes. On obtiendra aussi un jeu simulé de N valeurs de la pente et de l'ordonnée à l'origine qui nous servirons ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réalisation des régression linéaire. polyfit peut faire les N régressions, tant que les abscisses ne changent pas\n",
    "# Ce qui est le cas ici\n",
    "# On doit par contre transposer le tableau des valeurs de C (inverser lignes et colonnes)\n",
    "p_sim = np.polyfit(A, C_sim.transpose(), 1)\n",
    "\n",
    "\n",
    "pente_m = np.mean(p_sim[0])\n",
    "ordo_m = np.mean(p_sim[1])\n",
    "pente_u = np.std(p_sim[0], ddof=1)\n",
    "ordo_u = np.std(p_sim[1], ddof=1)\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(\"Pente = {:.4f} +/- {:.4f} 10^-5 mol/L\".format(pente_m, pente_u))\n",
    "print(\"Ordonnée à l'origine = {:.4f} +/- {:.4f} 10^-5 mol/L\".format(ordo_m, ordo_u))\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "Histogrammes des valeurs simulées\n",
    "\"\"\"\n",
    "f, ax = plt.subplots(1, 2, figsize=(9, 6))\n",
    "f.suptitle(\"Distribution des valeurs simulées\")\n",
    "\n",
    "# Pente\n",
    "ax[0].set_xlabel('Pente(1e-5 mol/L)')\n",
    "ax[0].hist(p_sim[0], bins='rice')\n",
    "\n",
    "# Pente\n",
    "ax[1].set_xlabel('Ordonnée(1e-5 mol/L)')\n",
    "ax[1].hist(p_sim[1], bins='rice')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-director",
   "metadata": {},
   "source": [
    "On remarque que la droite ajustée ne passe pas par l'origine, même en tenant compte des incertitudes de mesures. Heureusement, la régression linéaire permet de travailler malgré le biais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vérification de l'ajustement par tracé graphique et calcul des écarts normalisés.\n",
    "\"\"\"\n",
    "f, ax = plt.subplots(2, 1, figsize=(9, 6), sharex='col')  # Tracé en partageant les abscisses sur les deux axes.\n",
    "f.suptitle(\"Ajustement linéaire\")\n",
    "\n",
    "\"\"\"\n",
    "Tracé de la droite d'ajustment\n",
    "On va pousser plus loin l'analyse en estimant l'incertitude sur les points ajustés.\n",
    "On s'en servira dans les écarts normalisés notamment.\n",
    "\"\"\"\n",
    "\n",
    "C_adj_sim = np.zeros((N, n_mes))\n",
    "for i in range(n_mes):\n",
    "    C_adj_sim[:, i] = p_sim[0] * A[i] + p_sim[1]  # Calcul des N valeurs ajustées pour chaque distance\n",
    "\n",
    "\n",
    "C_adj_m = C_adj_sim.mean(axis=0)  # Moyenne sur les N valeurs (suivant les colonnes :  axis = 0)\n",
    "C_adj_u = C_adj_sim.std(ddof=1, axis=0)  # Moyenne sur les N valeurs (suivant les colonnes :  axis = 0)\n",
    "\n",
    "ax[0].set_xlabel(\"A\")\n",
    "ax[0].set_ylabel(\"C(1e-5 mol/L)\")\n",
    "ax[0].errorbar(A, C, yerr=uC, marker='+', markersize=2, linestyle='')\n",
    "ax[0].plot(A, C_adj_m, linestyle=':', linewidth=1, color='red')\n",
    "\n",
    "\n",
    "\"\"\"Tracé des écarts normalisés\"\"\"\n",
    "en = (C - C_adj_m) / (np.sqrt(uC ** 2 + C_adj_u ** 2))\n",
    "\n",
    "\n",
    "ax[1].set_xlabel(\"A\")\n",
    "ax[1].set_ylabel(\"EN\")\n",
    "ax[1].plot(A, en, linestyle='', marker='+', color='red')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-delta",
   "metadata": {},
   "source": [
    "L'analyse de la droite d'ajustement est délicate car les incertitudes sont très faibles. L'analyse des écarts normalisés ne laisse par contre pas de doute, le modèle ajusté est compatible avec les résultats. One ne cherche pas vraiment une valeur particulière de la pente (même si le coefficient du bleu de patenté est tabulé). On va maintenant pouvoir utiliser cette droite d'ajustement.\n",
    "\n",
    "\n",
    "\n",
    "## Utilisation de la droite d'ajustement.\n",
    "On se propose d'utiliser la droite d'ajustement comme courbe d'étalonnage pour déterminer une concentration à partir dela mesure d'une absorbance\n",
    "\n",
    "Si la détermination de $C$ connaissant la pente et l'ordonnée à l'origine précédente ne pose pas de problème. On va voir comme utiliser les valeurs simulées précédentes pour estimer les incertitudes de mesure.\n",
    "\n",
    "On montrera aussi graphiquement ces incertitudes de mesure sur la droite d'étalonnage. Pour produire une courbe d'étalonnage __avec incertitudes de mesures__.\n",
    "\n",
    "### Détermination la concentration pour une mesure\n",
    "\n",
    "On commence par supposer qu'on a mesuré l'abosrbance $A$. On prendra $A = 0.523$ pour l'exemple. On va simuler le calcul de $C$ N fois à partir des valeurs simulées de la pente et de l'ordonnées à l'origine ($C = aA + b$). Les statistiques obtenues nous permettront d'obtenir une estimation de $C$ et de son incertitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test = 0.523  # Distance en centimètre\n",
    "C_sim = p_sim[0] * A_test + p_sim[1]  # Simulation des concentrations\n",
    "\n",
    "C_m = np.mean(C_sim)  # Estimation de la concentration moyenne\n",
    "C_u = np.std(C_sim, ddof=1)  # Estimation de l'écart-type\n",
    "\n",
    "print(\"-----------------------------\")\n",
    "print(\"Concentration estimée = ({:.3f} +/- {:.3f}) 10^-5 mol/L\".format(C_m, C_u))\n",
    "print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-victory",
   "metadata": {},
   "source": [
    "### Courbe d'étalonnage avec incertitude\n",
    "Pour représenter la courbe avec incertitude (on imagine qu'elle serait donnée ensuite à un autre expérimentateur qui n'aurait pas à faire cet étalonnage), on va représenter les _fuseaux_ donnant les valeurs $C_{mes} \\pm u(C)$ estimé pour chaque valeur d'absorbance __dans la zone d'étude__.\n",
    "\n",
    "```{margin}\n",
    "Il est délicat d'extrapoler en dessous de $A_{min}$ et au dessus de $A_{max}$, des phénomènes supplémentaires peuvent rendre faux le modèle affine. On ne l'a pas testé.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "NA = 100  # Nombre de valeurs d'absorbance qu'on va tester\n",
    "A_courbe = np.linspace(min(A), max(A), NA)  # On trace les fuseaux pour la zone d'étude.\n",
    "\n",
    "\"\"\"\n",
    "On reprend la même méthode que précédemment mais pour chaque valeur de A. On va donc obtenir \n",
    "un vecteur de valeurs pour C et son incertitude\n",
    "\"\"\"\n",
    "\n",
    "C_courbe_sim = np.zeros((NA, N))  # Tableau de 0 où on va stocker les valeurs simulées de C pour chaque absorbance\n",
    "for i in range(NA):\n",
    "    C_courbe_sim[i] = p_sim[0] * A_courbe[i] + p_sim[1]  # Simulation des concentrations pour chaque valeur de A\n",
    "\n",
    "C_courbe_m = np.mean(C_courbe_sim, axis=1)  # Estimation de la concentration moyenne pour chaque valeur de A (par colonne)\n",
    "C_courbe_u = np.std(C_courbe_sim, ddof=1, axis=1)  # Estimation de l'écart-type pour chaque valeur de A (par colonne=)\n",
    "\n",
    "C_mean = pente_m * A_courbe + ordo_m  # Droite ajustée\n",
    "C_min = C_courbe_m - C_courbe_u # Limite basse des valeurs données par l'incertitude\n",
    "C_max = C_courbe_m + C_courbe_u # Limite basse des valeurs données par l'incertitude\n",
    "\n",
    "\"\"\"\n",
    "Tracé graphique de la droite d'étalonnage avec le fuseau donnant les incertitudes\n",
    "\"\"\"\n",
    "f, ax = plt.subplots()\n",
    "f.suptitle(\"Courbe d'étalonnage pour dosage par absorbance\")\n",
    "ax.set_xlabel(\"A\")\n",
    "ax.set_ylabel(\"C(10^-5 mol/L)\")\n",
    "\n",
    "ax.plot(A_courbe, C_mean, label=\"Droite étalon\", color='black', linewidth=1)  # Droite d'ajustement\n",
    "\n",
    "# Première méthode : on trace les deux courbes hautes et basses\n",
    "ax.plot(A_courbe, C_min, color='blue', linewidth=.5)  # Cmes - u(C)\n",
    "ax.plot(A_courbe, C_max, color='blue', linewidth=.5)  # Cmes + u(C)\n",
    "\n",
    "# Deuxième méthode : la fonction fill_between, remplit de couleur l'espace entre 2 courbes\n",
    "ax.fill_between(A_courbe, C_min, C_max, color='cyan', linewidth=1, label=\"Incertitudes sur la concentration\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,md:myst",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.10.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "source_map": [
   15,
   26,
   35,
   40,
   60,
   67,
   72,
   78,
   111,
   115,
   153,
   169,
   181,
   191
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}